{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 처리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 크롤링 모듈\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# 시간처리 모듈\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# 텍스트 처리\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "# 한 셀에서 여러 output 한번에 표시\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-certificate",
   "metadata": {},
   "source": [
    "# 크롤링+불용어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_list = [\"그리핀도르\",\"후플푸프\",\"래번클로\",\"슬리데린\"]\n",
    "\n",
    "list_name = []\n",
    "list_house = []\n",
    "list_description = []\n",
    "\n",
    "for house in house_list :\n",
    "    \n",
    "    print(\"{}의 학생들을 크롤링 합니다\".format(house))\n",
    "    webpage = requests.get('https://namu.wiki/w/' + house)\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    for a in soup.select(\"td > div.wiki-paragraph > div > a.wiki-link-internal\") :\n",
    "        list_name.append(a[\"title\"])\n",
    "        list_house.append(house)\n",
    "    \n",
    "    \n",
    "print(\"학생들의 description을 크롤링 합니다\")\n",
    "for name in list_name:\n",
    "    try :\n",
    "        webpage = requests.get('https://namu.wiki/w/' + name)\n",
    "        soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "        name_contents = soup.find('div', {'class':'wiki-heading-content'})\n",
    "        list_description.append(name_contents.text)\n",
    "        time.sleep(0.7)\n",
    "    except:\n",
    "        list_description.append('no data')\n",
    "    \n",
    "print(\"불용어 처리를 시작합니다\")\n",
    "\n",
    "del_list = [\"하다\",\"있다\",\"되다\",\"이다\",\"돼다\",\"않다\",\"그렇다\",\"아니다\",\"이렇다\",\"어떻다\",\"되어다\",\"같다\",\n",
    "            \"호그와트\",\"래번클로\",\"후플푸프\",\"슬리데린\",\"그리핀도르\",\n",
    "            '이', '그', '저', '것', '건', '때', '더', '걸', '중', '별', '거',\n",
    "            \"시리즈\",\"등장인물\",\"등장\",\"인물\",\"해리\",\"포터\"]\n",
    "\n",
    "list_cleaned = []    \n",
    "for i,content in enumerate(list_description) : \n",
    "    twitter = Twitter()\n",
    "    each_description_pos_tagged = twitter.pos(content , norm=True , stem=True)\n",
    "\n",
    "    globals()[\"word_cleaned_{}\".format(i)] = []\n",
    "    for word in each_description_pos_tagged :\n",
    "        if (word[1] in [\"Noun\",\"Adjective\",\"Verb\"])&(len(word[0]) != 1)&(word[0] not in del_list) :\n",
    "            globals()[\"word_cleaned_{}\".format(i)].append(word[0])\n",
    "    \n",
    "    list_cleaned.append(\" \".join(globals()[\"word_cleaned_{}\".format(i)]))\n",
    "\n",
    "print(\"불용어 처리 완료!\")\n",
    "\n",
    "# df 생성\n",
    "df = pd.DataFrame({\n",
    "    \"name\" : list_name,\n",
    "    \"house\" : list_house,\n",
    "    \"description\" : list_cleaned\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-teacher",
   "metadata": {},
   "source": [
    "# 추가적인 전처리 차근차근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 87번처럼, 불용어 처리 후에 description이 비어있는 학생들이 있다 (개요/소개가 '해리포터 시리즈의 등장인물'로만 되어있던 학생들)\n",
    "# 래번클로 중 except \"no data\" 처리된 학생의 description 역시 비어있는 것을 확인할 수 있다\n",
    "df[df[\"house\"] == \"래번클로\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df.copy()\n",
    "\n",
    "# description이 빈 행의 개수 파악\n",
    "df_result[df_result['description'] == \"\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# description이 비어있지 않은 인덱스만 남기기\n",
    "df_result = df_result[df_result['description'] != \"\"].reset_index(drop=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result.to_excel(\"data_harrypotter.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-daisy",
   "metadata": {},
   "source": [
    "# (Run)크롤링+불용어 처리+전처리 냅다 모아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "house_list = [\"그리핀도르\",\"후플푸프\",\"래번클로\",\"슬리데린\"]\n",
    "\n",
    "list_name = []\n",
    "list_house = []\n",
    "list_description = []\n",
    "\n",
    "for house in house_list :\n",
    "    \n",
    "    print(\"{}의 학생들을 크롤링 합니다\".format(house))\n",
    "    webpage = requests.get('https://namu.wiki/w/' + house)\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    for a in soup.select(\"td > div.wiki-paragraph > div > a.wiki-link-internal\") :\n",
    "        list_name.append(a[\"title\"])\n",
    "        list_house.append(house)\n",
    "    \n",
    "    \n",
    "print(\"학생들의 description을 크롤링 합니다\")\n",
    "for name in list_name:\n",
    "    try :\n",
    "        webpage = requests.get('https://namu.wiki/w/' + name)\n",
    "        soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "        name_contents = soup.find('div', {'class':'wiki-heading-content'})\n",
    "        list_description.append(name_contents.text)\n",
    "        time.sleep(0.7)\n",
    "    except:\n",
    "        list_description.append('no data')\n",
    "    \n",
    "print(\"불용어 처리를 시작합니다\")\n",
    "\n",
    "del_list = [\"하다\",\"있다\",\"되다\",\"이다\",\"돼다\",\"않다\",\"그렇다\",\"아니다\",\"이렇다\",\"어떻다\",\"되어다\",\"같다\",\n",
    "            \"호그와트\",\"래번클로\",\"후플푸프\",\"슬리데린\",\"그리핀도르\",\n",
    "            '이', '그', '저', '것', '건', '때', '더', '걸', '중', '별', '거',\n",
    "            \"시리즈\",\"등장인물\",\"등장\",\"인물\",\"해리\",\"포터\"]\n",
    "\n",
    "list_cleaned = []    \n",
    "for i,content in enumerate(list_description) : \n",
    "    twitter = Twitter()\n",
    "    each_description_pos_tagged = twitter.pos(content , norm=True , stem=True)\n",
    "\n",
    "    globals()[\"word_cleaned_{}\".format(i)] = []\n",
    "    for word in each_description_pos_tagged :\n",
    "        if (word[1] in [\"Noun\",\"Adjective\",\"Verb\"])&(len(word[0]) != 1)&(word[0] not in del_list) :\n",
    "            globals()[\"word_cleaned_{}\".format(i)].append(word[0])\n",
    "    \n",
    "    list_cleaned.append(\" \".join(globals()[\"word_cleaned_{}\".format(i)]))\n",
    "\n",
    "print(\"불용어 처리 완료!\")\n",
    "\n",
    "# df 생성\n",
    "df = pd.DataFrame({\n",
    "    \"name\" : list_name,\n",
    "    \"house\" : list_house,\n",
    "    \"description\" : list_cleaned\n",
    "})\n",
    "df\n",
    "\n",
    "df_result = df.copy()\n",
    "\n",
    "# description이 비어있지 않은 인덱스만 남기기\n",
    "df_result = df_result[df_result['description'] != \"\"].reset_index(drop=True)\n",
    "df_result\n",
    "\n",
    "df_result.to_excel(\"data_harrypotter.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-uganda",
   "metadata": {},
   "source": [
    "# 유사도 분석 차근차근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "유사도 분석\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df_all = df_result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 받고 df_all에 추가하기\n",
    "name = input('이름을 입력해주세요 : ')\n",
    "wish = input('해리포터 영화 속으로 들어갈 수 있다면 무엇을 해보고 싶으신가요?! : ')\n",
    "df_all = df_all.append({'name' : name , 'house' : '머글 기숙사', 'description' : wish},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 학생들의 description을 벡터 공간(array)로 표현\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_matrix = vectorizer.fit_transform(df_all[\"description\"])\n",
    "x_matrix.shape\n",
    "\n",
    "# 유사도(각 학생들을 서로 서로 비교한 결과값) array 생성\n",
    "cosine_matrix = cosine_similarity(x_matrix, x_matrix)\n",
    "cosine_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 번호 추출을 위해 시리즈 만들기\n",
    "for_index = pd.Series(df_all.index,index=df_all[\"name\"])\n",
    "for_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = for_index[name] # 내가 입력한 name의 index 번호 \n",
    "sim_scores = [(i,c) for i, c in enumerate(cosine_matrix[idx]) if i != idx] \n",
    "#내가 입력한 wish와 각 학생들의 description 유사도 값 쭈루룩(유사도 값이 1.0인, 내가 입력한 행은 제외)\n",
    "sim_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.iloc[61][\"name\"] # Roger Davies : He was the Captain of the Ravenclaw Quidditch team and played as a Chaser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse = True)\n",
    "sim_scores[:5] # cosine_similarity 상위 5위까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이름과 기숙사, 유사도 값을 포함한 dataframe 보여주기\n",
    "num = [i[0] for i in sim_scores[:5]]\n",
    "num\n",
    "\n",
    "simil_df = df_all.iloc[num].copy()\n",
    "del simil_df[\"description\"]\n",
    "simil_df[\"score\"] = [i[1] for i in sim_scores[:5]]\n",
    "simil_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-drunk",
   "metadata": {},
   "source": [
    "# (Run)차근차근 ㄴㄴ! 냅다 모아서 함수로 만들어버림!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "wrong-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result = pd.read_excel(\"data_harrypotter.xlsx\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "blond-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 이름과 기숙사, 유사도 값을 포함한 dataframe 출력하는 함수\n",
    "def WingardiumLeviosa(name,wish) :\n",
    "    df_all = df_result.copy() # 함수 안에서 사용할 dataframe copy\n",
    "    df_all = df_all.append({'name' : name , 'house' : '머글 기숙사', 'description' : wish},ignore_index=True)\n",
    "\n",
    "    # 각 학생들의 description을 벡터 공간(array)로 표현\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    x_matrix = vectorizer.fit_transform(df_all[\"description\"])\n",
    "\n",
    "    # 유사도(각 학생들을 서로 서로 비교한 결과값) array 생성\n",
    "    cosine_matrix = cosine_similarity(x_matrix, x_matrix)\n",
    "\n",
    "    for_index = pd.Series(df_all.index,index=df_all[\"name\"]) # index 번호 추출을 위해 시리즈 만들기\n",
    "    idx = for_index[name] # 내가 입력한 name의 index 번호 \n",
    "    sim_scores = [(i,c) for i, c in enumerate(cosine_matrix[idx]) if i != idx] # 내가 입력한 wish와 각 학생들의 description 유사도 값 쭈루룩(유사도 값이 1.0인, 내가 입력한 행은 제외)\n",
    "    sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse = True) # 유사도가 높은 순서대로 정렬\n",
    "    sim_scores[:5] # cosine_similarity 상위 5위까지\n",
    "\n",
    "    # 이름과 기숙사, 유사도 값을 포함한 dataframe 보여주기\n",
    "    num = [i[0] for i in sim_scores[:5]] # 상위 5위까지의 index 번호 리스트\n",
    "    df_simil = df_all.iloc[num].copy() # 상위 5위까지의 dataframe만 가져와 copy\n",
    "    del df_simil[\"description\"] # 출력에 불필요한 컬럼 지우기\n",
    "    df_simil[\"score\"] = [i[1] for i in sim_scores[:5]] #유사도값 컬럼 추가하기\n",
    "    \n",
    "    return df_simil\n",
    "    del df_all # 함수 안에서 사용한 dataframe copy본 없애기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-mason",
   "metadata": {},
   "source": [
    "# (Run)시현해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "particular-baltimore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이름을 입력해주세요 : 윤지윤\n",
      "해리포터 영화 속으로 들어갈 수 있다면 무엇을 해보고 싶으신가요?! : 님부스 2000 타고 퀴디치 경기 뛰기\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>house</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>로저 데이비스</td>\n",
       "      <td>래번클로</td>\n",
       "      <td>0.074881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>세드릭 디고리</td>\n",
       "      <td>후플푸프</td>\n",
       "      <td>0.073867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>케이티 벨</td>\n",
       "      <td>그리핀도르</td>\n",
       "      <td>0.066677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>찰리 위즐리</td>\n",
       "      <td>그리핀도르</td>\n",
       "      <td>0.044415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>블레이즈 자비니</td>\n",
       "      <td>슬리데린</td>\n",
       "      <td>0.042197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  house     score\n",
       "61   로저 데이비스   래번클로  0.074881\n",
       "37   세드릭 디고리   후플푸프  0.073867\n",
       "19     케이티 벨  그리핀도르  0.066677\n",
       "13    찰리 위즐리  그리핀도르  0.044415\n",
       "83  블레이즈 자비니   슬리데린  0.042197"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력을 받고 주문을 외쳐주세요\n",
    "name = input('이름을 입력해주세요 : ')\n",
    "wish = input('해리포터 영화 속으로 들어갈 수 있다면 무엇을 해보고 싶으신가요?! : ')\n",
    "WingardiumLeviosa(name,wish)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
